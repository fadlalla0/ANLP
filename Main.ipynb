{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571adbdd-e6e1-40e6-8782-f489ca09ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence, pad_sequence\n",
    "import torch\n",
    "from transformers import LongformerModel,LongformerConfig,LongformerTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.modules import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from typing import Tuple, List\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421060d7-afd2-4e93-b39b-b26cc8b0f57b",
   "metadata": {},
   "source": [
    "# Experiement configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05247b11-2806-43e0-9619-25a82136595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    config = argparse.ArgumentParser()\n",
    "    config.add_argument(\"--save-path\", default=\"./saved_models\", type=str)\n",
    "\n",
    "    # training\n",
    "    config.add_argument(\"--device\", default='1', type=str)\n",
    "    config.add_argument(\"--seed\", default=42, type=int)\n",
    "    config.add_argument(\"--batch-size\", default=4, type=int)\n",
    "    config.add_argument(\"--epochs\", default=2, type=int)\n",
    "    config.add_argument(\"--showtime\", default=2000, type=int)\n",
    "    config.add_argument(\"--base-encoder-lr\", default=1e-5, type=float)\n",
    "    config.add_argument(\"--longformer-base-encoder-lr\", default=1e-5, type=float)\n",
    "    config.add_argument(\"--finetune-lr\", default=1e-3, type=float)\n",
    "    config.add_argument(\"--warm-up\", default=5e-2, type=float)\n",
    "    config.add_argument(\"--weight-decay\", default=1e-5, type=float)\n",
    "    config.add_argument(\"--early-num\", default=5, type=int)\n",
    "    config.add_argument(\"--num-tags\", default=5, type=int)\n",
    "    config.add_argument(\"--threshold\", default=0.3, type=float)\n",
    "\n",
    "    config.add_argument(\"--hidden-size\", default=128, type=int)\n",
    "    config.add_argument(\"--layers\", default=2, type=int)\n",
    "    config.add_argument(\"--is-bi\", default=False, type=bool)\n",
    "    config.add_argument(\"--bert-output-size\", default=768, type=int)\n",
    "    config.add_argument(\"--mlp-size\", default=512, type=int)\n",
    "    config.add_argument(\"--scale-factor\", default=2, type=int)\n",
    "    config.add_argument(\"--dropout\", default=0.7, type=float)\n",
    "    config.add_argument(\"--max-grad-norm\", default=1.0, type=float)\n",
    "\n",
    "    config.add_argument(\"--num-heads\", default=4, type=int)\n",
    "    config.add_argument(\"--att_dropout\", default=0.1, type=float)\n",
    "\n",
    "    config.add_argument(\"--mrc_dropout\", type=float, default=0.7,\n",
    "                        help=\"mrc dropout rate\")\n",
    "    config.add_argument(\"--lstm_dropout\", type=float, default=0.4,\n",
    "                        help=\"lstm dropout rate\")\n",
    "    config.add_argument(\"--classifier_act_func\", type=str, default=\"gelu\")\n",
    "    config.add_argument(\"--classifier_intermediate_hidden_size\", type=int, default=128)\n",
    "    config.add_argument(\"--weight_start\", type=float, default=1.0)\n",
    "    config.add_argument(\"--weight_end\", type=float, default=1.0)\n",
    "    config.add_argument(\"--weight_span\", type=float, default=0.1)\n",
    "\n",
    "    # Use parse_known_args to ignore unrecognized arguments\n",
    "    config, _ = config.parse_known_args()\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c41063-4946-4a6c-bd3f-615b6670755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLinearClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_label):\n",
    "        super(SingleLinearClassifier, self).__init__()\n",
    "        self.num_label = num_label\n",
    "        self.classifier = nn.Linear(hidden_size, num_label)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        features_output = self.classifier(input_features)\n",
    "        return features_output\n",
    "\n",
    "\n",
    "class MultiNonLinearClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_label, dropout_rate, act_func=\"gelu\", intermediate_hidden_size=None):\n",
    "        super(MultiNonLinearClassifier, self).__init__()\n",
    "        self.num_label = num_label\n",
    "        self.intermediate_hidden_size = hidden_size if intermediate_hidden_size is None else intermediate_hidden_size\n",
    "        self.classifier1 = nn.Linear(hidden_size, self.intermediate_hidden_size)\n",
    "        self.classifier2 = nn.Linear(self.intermediate_hidden_size, self.num_label)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.act_func = act_func\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        features_output1 = self.classifier1(input_features)\n",
    "        if self.act_func == \"gelu\":\n",
    "            features_output1 = F.gelu(features_output1)\n",
    "        elif self.act_func == \"relu\":\n",
    "            features_output1 = F.relu(features_output1)\n",
    "        elif self.act_func == \"tanh\":\n",
    "            features_output1 = F.tanh(features_output1)\n",
    "        elif self.act_func == \"leakyrelu\":\n",
    "            features_output1 = F.leaky_relu(features_output1,0.2,inplace=True)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        features_output1 = self.dropout(features_output1)\n",
    "        features_output2 = self.classifier2(features_output1)\n",
    "        return features_output2\n",
    "\n",
    "\n",
    "\n",
    "class ThreeNonLinearClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_label, dropout_rate,intermediate_hidden_size_0,intermediate_hidden_size_1, act_func=\"gelu\"):\n",
    "        super(ThreeNonLinearClassifier, self).__init__()\n",
    "        self.num_label = num_label\n",
    "        self.intermediate_hidden_size_0 = intermediate_hidden_size_0\n",
    "        self.intermediate_hidden_size_1 = intermediate_hidden_size_1\n",
    "\n",
    "        self.classifier1 = nn.Linear(hidden_size, self.intermediate_hidden_size_0)\n",
    "        self.classifier2 = nn.Linear(self.intermediate_hidden_size_0, self.intermediate_hidden_size_1)\n",
    "        self.classifier3 = nn.Linear(self.intermediate_hidden_size_1, self.num_label)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.act_func = act_func\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        features_output1 = self.classifier1(input_features)\n",
    "        if self.act_func == \"gelu\":\n",
    "            features_output1 = F.gelu(features_output1)\n",
    "        elif self.act_func == \"relu\":\n",
    "            features_output1 = F.relu(features_output1)\n",
    "        elif self.act_func == \"tanh\":\n",
    "            features_output1 = F.tanh(features_output1)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        features_output1 = self.dropout(features_output1)\n",
    "        features_output2 = self.classifier2(features_output1)\n",
    "        if self.act_func == \"gelu\":\n",
    "            features_output2 = F.gelu(features_output2)\n",
    "        elif self.act_func == \"relu\":\n",
    "            features_output2 = F.relu(features_output2)\n",
    "        elif self.act_func == \"tanh\":\n",
    "            features_output2 = F.tanh(features_output2)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        features_output2 = self.dropout(features_output2)\n",
    "        features_output3 = self.classifier3(features_output2)\n",
    "        return features_output3\n",
    "\n",
    "class BERTTaggerClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_label, dropout_rate, act_func=\"gelu\", intermediate_hidden_size=None):\n",
    "        super(BERTTaggerClassifier, self).__init__()\n",
    "        self.num_label = num_label\n",
    "        self.intermediate_hidden_size = hidden_size if intermediate_hidden_size is None else intermediate_hidden_size\n",
    "        self.classifier1 = nn.Linear(hidden_size, self.intermediate_hidden_size)\n",
    "        self.classifier2 = nn.Linear(self.intermediate_hidden_size, self.num_label)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.act_func = act_func\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        features_output1 = self.classifier1(input_features)\n",
    "        if self.act_func == \"gelu\":\n",
    "            features_output1 = F.gelu(features_output1)\n",
    "        elif self.act_func == \"relu\":\n",
    "            features_output1 = F.relu(features_output1)\n",
    "        elif self.act_func == \"tanh\":\n",
    "            features_output1 = F.tanh(features_output1)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        features_output1 = self.dropout(features_output1)\n",
    "        features_output2 = self.classifier2(features_output1)\n",
    "        return features_output2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461b0d6-85a2-4f27-9349-21063b4affbe",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0becbc87-eef5-4748-ac6e-58d9a949f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags2id = {'O': 0, 'B-Review': 1, 'I-Review': 2, 'E-Review': 3, 'S-Review': 4,\n",
    "           'B-Reply': 1, 'I-Reply': 2, 'E-Reply': 3, 'S-Reply': 4,\n",
    "           'B': 1, 'I': 2, 'E': 3, 'S': 4}\n",
    "def spans_to_tags(spans, seq_len):\n",
    "    tags = [tags2id['O']] * seq_len\n",
    "    for span in spans:\n",
    "        tags[span[0]] = tags2id['B']\n",
    "        tags[span[0]:span[1]+1] = [tags2id['I']] * (span[1]-span[0]+1)\n",
    "        if span[0] == span[1]:\n",
    "            tags[span[0]] = tags2id['S']\n",
    "        else:\n",
    "            tags[span[0]] = tags2id['B']\n",
    "            tags[span[1]] = tags2id['E']\n",
    "    return tags\n",
    "\n",
    "\n",
    "def get_arg_span(bioes_tags):\n",
    "    start, end = None, None\n",
    "    arguments = []\n",
    "    in_entity_flag = False\n",
    "    for idx, tag in enumerate(bioes_tags):\n",
    "        if in_entity_flag == False:\n",
    "            if tag == 1: # B\n",
    "                in_entity_flag = True\n",
    "                start = idx\n",
    "            elif tag == 4: # S\n",
    "                start = idx\n",
    "                end = idx\n",
    "                arguments.append((start, end))\n",
    "                start = None\n",
    "                end = None\n",
    "        else:\n",
    "            if tag == 0: # O\n",
    "                in_entity_flag = False\n",
    "                start = None\n",
    "                end = None\n",
    "            elif tag == 1: # B\n",
    "                in_entity_flag = True\n",
    "                start = idx\n",
    "            elif tag == 3: # E\n",
    "                in_entity_flag = False\n",
    "                end = idx\n",
    "                arguments.append((start, end))\n",
    "                start = None\n",
    "                end = None\n",
    "            elif tag == 4: # S\n",
    "                in_entity_flag = False\n",
    "                start = idx\n",
    "                end = idx\n",
    "                arguments.append((start, end))\n",
    "                start = None\n",
    "                end = None\n",
    "    return arguments\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_arguments(bioes_list):\n",
    "    arguments_list = []\n",
    "    for pred_tags in bioes_list:\n",
    "        arguments = get_arg_span(pred_tags)\n",
    "        arguments_list.append(arguments)\n",
    "    return arguments_list\n",
    "\n",
    "def extract_span_arguments_yi(match_labels,start_labels,end_labels):\n",
    "    arguments_list = []\n",
    "    for match_l, start_l, end_l in zip(match_labels,start_labels,end_labels):\n",
    "        arguments = extract_flat_spans_yi( start_l, end_l,match_l)\n",
    "        arguments_list.append(arguments)\n",
    "    return arguments_list\n",
    "def extract_span_arguments(match_labels,start_labels,end_labels):\n",
    "    arguments_list = []\n",
    "    for match_l, start_l, end_l in zip(match_labels,start_labels,end_labels):\n",
    "        arguments = extract_flat_spans( start_l, end_l,match_l)\n",
    "        arguments_list.append(arguments)\n",
    "    return arguments_list\n",
    "\n",
    "def extract_span_arguments_nested(match_labels,start_labels,end_labels):\n",
    "    arguments_list = []\n",
    "    for match_l, start_l, end_l in zip(match_labels,start_labels,end_labels):\n",
    "        arguments = extract_flat_spans_nested( start_l, end_l,match_l)\n",
    "        arguments_list.append(arguments)\n",
    "    return arguments_list\n",
    "\n",
    "class Tag(object):\n",
    "    def __init__(self, term, tag, begin, end):\n",
    "        self.term = term\n",
    "        self.tag = tag\n",
    "        self.begin = begin\n",
    "        self.end = end\n",
    "\n",
    "    def to_tuple(self):\n",
    "        return tuple([self.term, self.begin, self.end])\n",
    "\n",
    "    def __str__(self):\n",
    "        return str({key: value for key, value in self.__dict__.items()})\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str({key: value for key, value in self.__dict__.items()})\n",
    "\n",
    "\n",
    "def bmes_decode(char_label_list: List[Tuple[str, str]]) -> List[Tag]:\n",
    "    \"\"\"\n",
    "    decode inputs to tags\n",
    "    Args:\n",
    "        char_label_list: list of tuple (word, bmes-tag)\n",
    "    Returns:\n",
    "        tags\n",
    "    Examples:\n",
    "        >>> x = [(\"Hi\", \"O\"), (\"Beijing\", \"S-LOC\")]\n",
    "        >>> bmes_decode(x)\n",
    "        [{'term': 'Beijing', 'tag': 'LOC', 'begin': 1, 'end': 2}]\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    length = len(char_label_list)\n",
    "    tags = []\n",
    "    while idx < length:\n",
    "        term, label = char_label_list[idx]\n",
    "        current_label = label[0]\n",
    "\n",
    "        # correct labels\n",
    "        if idx + 1 == length and current_label == \"B\":\n",
    "            current_label = \"S\"\n",
    "\n",
    "        # merge chars\n",
    "        if current_label == \"O\":\n",
    "            idx += 1\n",
    "            continue\n",
    "        if current_label == \"S\":\n",
    "            tags.append(Tag(term, label[2:], idx, idx + 1))\n",
    "            idx += 1\n",
    "            continue\n",
    "        if current_label == \"B\":\n",
    "            end = idx + 1\n",
    "            while end + 1 < length and char_label_list[end][1][0] == \"M\":\n",
    "                end += 1\n",
    "            if char_label_list[end][1][0] == \"E\":  # end with E\n",
    "                entity = \"\".join(char_label_list[i][0] for i in range(idx, end + 1))\n",
    "                tags.append(Tag(entity, label[2:], idx, end + 1))\n",
    "                idx = end + 1\n",
    "            else:  # end with M/B\n",
    "                entity = \"\".join(char_label_list[i][0] for i in range(idx, end))\n",
    "                tags.append(Tag(entity, label[2:], idx, end))\n",
    "                idx = end\n",
    "            continue\n",
    "        else:\n",
    "            idx += 1\n",
    "            continue\n",
    "            # print(\"?\")\n",
    "            # raise Exception(\"Invalid Inputs\")\n",
    "    return tags\n",
    "\n",
    "def extract_flat_spans_nested(start_pred, end_pred, match_pred,  pseudo_tag = \"TAG\"):\n",
    "    seq_len = start_pred.size()[0]\n",
    "\n",
    "    start_l_mask = [[1 for i in range(seq_len)]]\n",
    "    end_l_mask = [[1 for i in range(seq_len)]]\n",
    "\n",
    "    start_label_mask = torch.LongTensor(start_l_mask).cuda()\n",
    "    end_label_mask = torch.LongTensor(end_l_mask).cuda()\n",
    "\n",
    "    start_label_mask = start_label_mask.bool()\n",
    "    end_label_mask = end_label_mask.bool()\n",
    "    bsz, seq_len = start_label_mask.size()\n",
    "\n",
    "\n",
    "    start_preds = start_pred.bool().unsqueeze(0).cuda()\n",
    "    end_preds = end_pred.bool().unsqueeze(0).cuda()\n",
    "    match_pred_s=match_pred.bool().unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "    match_preds = (match_pred_s & start_preds.unsqueeze(-1).expand(-1, -1, seq_len) & end_preds.unsqueeze(1).expand(-1, seq_len, -1))\n",
    "    match_label_mask = (start_label_mask.unsqueeze(-1).expand(-1, -1, seq_len) & end_label_mask.unsqueeze(1).expand(-1, seq_len, -1))\n",
    "    match_label_mask = torch.triu(match_label_mask, 0)  # start should be less or equal to end\n",
    "    match_preds = match_label_mask & match_preds\n",
    "    match_pos_pairs = np.transpose(np.nonzero(match_preds.cpu().numpy())).tolist()\n",
    "    return [(pos[1], pos[2]) for pos in match_pos_pairs]\n",
    "\n",
    "def extract_flat_spans(start_pred, end_pred, match_pred,  pseudo_tag = \"TAG\"):\n",
    "    \"\"\"\n",
    "    Extract flat-ner spans from start/end/match logits\n",
    "    Args:\n",
    "        start_pred: [seq_len], 1/True for start, 0/False for non-start\n",
    "        end_pred: [seq_len, 2], 1/True for end, 0/False for non-end\n",
    "        match_pred: [seq_len, seq_len], 1/True for match, 0/False for non-match\n",
    "        label_mask: [seq_len], 1 for valid boundary.\n",
    "    Returns:\n",
    "        tags: list of tuple (start, end)\n",
    "    Examples:\n",
    "        >>> start_pred = [0, 1]\n",
    "        >>> end_pred = [0, 1]\n",
    "        >>> match_pred = [[0, 0], [0, 1]]\n",
    "        >>> label_mask = [1, 1]\n",
    "        >>> extract_flat_spans(start_pred, end_pred, match_pred, label_mask)\n",
    "        [(1, 2)]\n",
    "    \"\"\"\n",
    "    pseudo_input = \"a\"\n",
    "\n",
    "    label_mask=[1]*len(start_pred) #TODO\n",
    "\n",
    "    bmes_labels = [\"O\"] * len(start_pred)\n",
    "    start_positions = [idx for idx, tmp in enumerate(start_pred) if tmp and label_mask[idx]]\n",
    "    end_positions = [idx for idx, tmp in enumerate(end_pred) if tmp and label_mask[idx]]\n",
    "\n",
    "    for start_item in start_positions:\n",
    "        bmes_labels[start_item] = f\"B-{pseudo_tag}\"\n",
    "    for end_item in end_positions:\n",
    "        bmes_labels[end_item] = f\"E-{pseudo_tag}\"\n",
    "\n",
    "    for tmp_start in start_positions:\n",
    "        tmp_end = [tmp for tmp in end_positions if tmp >= tmp_start]\n",
    "        if len(tmp_end) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_end = min(tmp_end)\n",
    "        if match_pred[tmp_start][tmp_end]:\n",
    "            if tmp_start != tmp_end:\n",
    "                for i in range(tmp_start+1, tmp_end):\n",
    "                    bmes_labels[i] = f\"M-{pseudo_tag}\"\n",
    "            else:\n",
    "                bmes_labels[tmp_end] = f\"S-{pseudo_tag}\"\n",
    "\n",
    "    tags = bmes_decode([(pseudo_input, label) for label in bmes_labels])\n",
    "\n",
    "    return [(entity.begin, entity.end-1) for entity in tags]\n",
    "\n",
    "\n",
    "def extract_flat_spans_yi(start_pred, end_pred, match_pred):\n",
    "    \"\"\"\n",
    "    Extract flat-ner spans from start/end/match logits\n",
    "    Args:\n",
    "        start_pred: [seq_len], 1/True for start, 0/False for non-start\n",
    "        end_pred: [seq_len, 2], 1/True for end, 0/False for non-end\n",
    "        match_pred: [seq_len, seq_len], 1/True for match, 0/False for non-match\n",
    "        label_mask: [seq_len], 1 for valid boundary.\n",
    "    Returns:\n",
    "        tags: list of tuple (start, end)\n",
    "    Examples:\n",
    "        >>> start_pred = [0, 1]\n",
    "        >>> end_pred = [0, 1]\n",
    "        >>> match_pred = [[0, 0], [0, 1]]\n",
    "        >>> label_mask = [1, 1]\n",
    "        >>> extract_flat_spans(start_pred, end_pred, match_pred, label_mask)\n",
    "        [(1, 2)]\n",
    "    \"\"\"\n",
    "    pseudo_input = \"a\"\n",
    "\n",
    "    label_mask=[1]*len(start_pred) #TODO\n",
    "\n",
    "    bmes_labels = [\"O\"] * len(start_pred)\n",
    "    start_positions = [idx for idx, tmp in enumerate(start_pred) if tmp and label_mask[idx]]\n",
    "    end_positions = [idx for idx, tmp in enumerate(end_pred) if tmp and label_mask[idx]]\n",
    "\n",
    "    for start_item in start_positions:\n",
    "        bmes_labels[start_item] = f\"B\"\n",
    "    for end_item in end_positions:\n",
    "        bmes_labels[end_item] = f\"E\"\n",
    "\n",
    "    for tmp_start in start_positions:\n",
    "        tmp_end = [tmp for tmp in end_positions if tmp >= tmp_start]\n",
    "        if len(tmp_end) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_end = min(tmp_end)\n",
    "        if match_pred[tmp_start][tmp_end]:\n",
    "            if tmp_start != tmp_end:\n",
    "                for i in range(tmp_start+1, tmp_end):\n",
    "                    bmes_labels[i] = f\"I\"\n",
    "            else:\n",
    "                bmes_labels[tmp_end] = f\"S\"\n",
    "\n",
    "    tags = get_arg_span([tags2id[label] for label in bmes_labels])\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b3355-f517-43d0-9279-3e3c9f576f16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2ad14f-d7e8-4c1a-8181-4614426d5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = config.layers\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.mlp_size = config.mlp_size\n",
    "        self.dropout = nn.Dropout(p=config.dropout)\n",
    "        self.scale_factor = config.scale_factor\n",
    "\n",
    "        self.special_tokens_yi = ['[TAB]', '[LINE]',\n",
    "                                  '[EQU]', '[URL]', '[NUM]',\n",
    "                                  '[SPE]', '<sep>', '[q]']\n",
    "        self.special_tokens_dict_yi = {'additional_special_tokens': self.special_tokens_yi}\n",
    "\n",
    "        self.longtokenizer = LongformerTokenizer.from_pretrained(\n",
    "            'allenai/longformer-base-4096')\n",
    "        self.longtokenizer.add_special_tokens(self.special_tokens_dict_yi) \n",
    "\n",
    "        self.longformerconfig = LongformerConfig.from_pretrained(\n",
    "            'allenai/longformer-base-4096')\n",
    "        self.longformerconfig.attention_mode = 'sliding_chunks'\n",
    "        self.longformerconfig.attention_window = [8,8,8,8,8,8,8,8,8,8,8,8]\n",
    "        self.attentionwindow = self.longformerconfig.attention_window[0]\n",
    "\n",
    "        self.longformer = LongformerModel.from_pretrained(\n",
    "            'allenai/longformer-base-4096', config=self.longformerconfig)\n",
    "\n",
    "        self.longformer.resize_token_embeddings(len(self.longtokenizer))\n",
    "\n",
    "\n",
    "        self.am_bilstm = nn.LSTM(config.bert_output_size, config.hidden_size, \\\n",
    "                                 num_layers=1, bidirectional=config.is_bi, batch_first=True)\n",
    "\n",
    "        self.start_outputs = nn.Linear(config.hidden_size, 1)\n",
    "        self.end_outputs = nn.Linear(config.hidden_size, 1)\n",
    "        self.span_embedding = MultiNonLinearClassifier(config.hidden_size*2, 1, config.mrc_dropout,\n",
    "                                                       intermediate_hidden_size=128)#256\n",
    "\n",
    "        self.span_loss_candidates = [\"all\", \"pred_and_gold\", \"pred_gold_random\", \"gold\"][0] \n",
    "\n",
    "        self.bce_loss = BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "        self.weight_start = config.weight_start\n",
    "        self.weight_end = config.weight_end\n",
    "        self.weight_span = config.weight_span\n",
    "\n",
    "\n",
    "    def compute_loss(self, start_logits, end_logits, span_logits,\n",
    "                     start_labels, end_labels, match_labels):\n",
    "\n",
    "        batch_size, seq_len = start_logits.size()\n",
    "\n",
    "        start_l_mask = torch.ones([batch_size, seq_len],dtype=torch.long)\n",
    "        end_l_mask =  torch.ones([batch_size, seq_len],dtype=torch.long)\n",
    "\n",
    "        start_label_mask = torch.LongTensor(start_l_mask).cuda()\n",
    "        end_label_mask = torch.LongTensor(end_l_mask).cuda()\n",
    "\n",
    "        start_float_label_mask = start_label_mask.view(-1).float()\n",
    "        end_float_label_mask = end_label_mask.view(-1).float()\n",
    "        match_label_row_mask = start_label_mask.bool().unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "        match_label_col_mask = end_label_mask.bool().unsqueeze(-2).expand(-1, seq_len, -1)\n",
    "        match_label_mask = match_label_row_mask & match_label_col_mask\n",
    "        match_label_mask = torch.triu(match_label_mask, 0)  \n",
    "\n",
    "        if self.span_loss_candidates == \"all\":\n",
    "            # naive mask\n",
    "            float_match_label_mask = match_label_mask.view(batch_size, -1).float()\n",
    "        else:\n",
    "            start_preds = start_logits > 0\n",
    "            end_preds = end_logits > 0\n",
    "            if self.span_loss_candidates == \"gold\":\n",
    "                match_candidates = ((start_labels.unsqueeze(-1).expand(-1, -1, seq_len) > 0)\n",
    "                                    & (end_labels.unsqueeze(-2).expand(-1, seq_len, -1) > 0))\n",
    "            elif self.span_loss_candidates == \"pred_gold_random\":\n",
    "                gold_and_pred = torch.logical_or(\n",
    "                    (start_preds.unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "                     & end_preds.unsqueeze(-2).expand(-1, seq_len, -1)),\n",
    "                    (start_labels.unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "                     & end_labels.unsqueeze(-2).expand(-1, seq_len, -1))\n",
    "                )\n",
    "                data_generator = torch.Generator()\n",
    "                data_generator.manual_seed(0)\n",
    "                random_matrix = torch.empty(batch_size, seq_len, seq_len).uniform_(0, 1)\n",
    "                random_matrix = torch.bernoulli(random_matrix, generator=data_generator).long()\n",
    "                random_matrix = random_matrix.cuda()\n",
    "                match_candidates = torch.logical_or(\n",
    "                    gold_and_pred, random_matrix\n",
    "                )\n",
    "            else:\n",
    "                match_candidates = torch.logical_or(\n",
    "                    (start_preds.unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "                     & end_preds.unsqueeze(-2).expand(-1, seq_len, -1)),\n",
    "                    (start_labels.unsqueeze(-1).expand(-1, -1, seq_len)\n",
    "                     & end_labels.unsqueeze(-2).expand(-1, seq_len, -1))\n",
    "                )\n",
    "            match_label_mask = match_label_mask & match_candidates\n",
    "            float_match_label_mask = match_label_mask.view(batch_size, -1).float()\n",
    "\n",
    "        start_loss = self.bce_loss(start_logits.view(-1), start_labels.view(-1).float())\n",
    "        start_loss = (start_loss * start_float_label_mask).sum() / start_float_label_mask.sum()\n",
    "        end_loss = self.bce_loss(end_logits.view(-1), end_labels.view(-1).float())\n",
    "        end_loss = (end_loss * end_float_label_mask).sum() / end_float_label_mask.sum()\n",
    "        match_loss = self.bce_loss(span_logits.view(batch_size, -1), match_labels.view(batch_size, -1).float())\n",
    "        match_loss = match_loss * float_match_label_mask\n",
    "        match_loss = match_loss.sum() / (float_match_label_mask.sum() + 1e-10)\n",
    "\n",
    "        return start_loss, end_loss, match_loss\n",
    "\n",
    "    def bert_emb_for_task1(self, para_tokens_list):\n",
    "        para_len_list = [len(para) for para in para_tokens_list]\n",
    "        max_para_len = max(para_len_list)\n",
    "\n",
    "        question_tokens = '[q]'\n",
    "        question_tokens_cls_sep = self.longtokenizer.cls_token + ' ' + question_tokens + ' ' + self.longtokenizer.sep_token \n",
    "        question_ids = self.longtokenizer.convert_tokens_to_ids(question_tokens_cls_sep.split(' '))\n",
    "        question_length = len(question_ids)\n",
    "\n",
    "        sent_tokens_list = [sent for para in para_tokens_list for sent in para]\n",
    "        sent_length_list = [len(sent.split(' ')) for para in para_tokens_list for sent in para]\n",
    "        passage_tokens = ' '.join(sent_tokens_list)\n",
    "        passage_tokens_cls_sep = self.longtokenizer.cls_token + ' ' + passage_tokens + ' ' + self.longtokenizer.sep_token\n",
    "\n",
    "        sent_ids = self.longtokenizer.convert_tokens_to_ids(passage_tokens_cls_sep.split(' '))  # !\n",
    "\n",
    "        question_sents_ids = [question_ids + sent_ids]\n",
    "\n",
    "        qs_ids_padding_list, qs_mask_list, max_len = self.padding_and_mask_with_return(question_sents_ids) \n",
    "        qs_ids_padding_tensor = torch.tensor(qs_ids_padding_list).cuda()\n",
    "        qs_mask_tensor = torch.tensor(qs_mask_list).cuda()\n",
    "\n",
    "        _, global_att_mask = self.padding_and_mask_to_max_lenth([question_ids], max_len) \n",
    "        global_att_mask_tensor = torch.tensor(global_att_mask).cuda()\n",
    "\n",
    "        try:\n",
    "\n",
    "            longformer_outputs = self.longformer(qs_ids_padding_tensor,\n",
    "                                                 attention_mask=qs_mask_tensor,\n",
    "                                                 global_attention_mask=global_att_mask_tensor)\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "        last_hidden_state = longformer_outputs[0] \n",
    "        last_hidden_state_for_s = last_hidden_state[:, (question_length + 1):-1, :]\n",
    "\n",
    "        sen_emb_list = []\n",
    "        start_index = 0\n",
    "        end_index = 0\n",
    "        for i in range(0, len(sent_length_list)):\n",
    "            end_index = start_index + sent_length_list[i]\n",
    "            last_h_temp = last_hidden_state_for_s[:, start_index:end_index, :]\n",
    "            sen_emb_list.append(last_h_temp.mean(dim=-2))\n",
    "            start_index = end_index\n",
    "\n",
    "        sent_emb = torch.cat(sen_emb_list, dim=0)\n",
    "\n",
    "        sent_emb = self.dropout(sent_emb)\n",
    "        return sent_emb\n",
    "\n",
    "    def bert_emb_for_task2(self, para_tokens_list,argument_para_tokens_list):\n",
    "        para_len_list = [len(para) for para in para_tokens_list]\n",
    "        max_para_len = max(para_len_list)\n",
    "\n",
    "        argument_tokens=' '.join(argument_para_tokens_list)\n",
    "        argument_tokens_cls_sep=self.longtokenizer.cls_token +' '+argument_tokens+' '+self.longtokenizer.sep_token\n",
    "        argument_ids=self.longtokenizer.convert_tokens_to_ids(argument_tokens_cls_sep.split(' '))\n",
    "        argument_length=len(argument_ids)\n",
    "\n",
    "        sent_tokens_list = [sent for para in para_tokens_list for sent in para]\n",
    "        sent_length_list = [len(sent.split(' ')) for para in para_tokens_list for sent in para]\n",
    "        passage_tokens=' '.join(sent_tokens_list)\n",
    "        passage_tokens_cls_sep=self.longtokenizer.sep_token +' '+passage_tokens+' '+self.longtokenizer.sep_token \n",
    "        sent_ids = self.longtokenizer.convert_tokens_to_ids(passage_tokens_cls_sep.split(' '))\n",
    "\n",
    "        pair_ids=[argument_ids+sent_ids]\n",
    "\n",
    "\n",
    "        pair_ids_padding_list, pair_mask_list,max_len = self.padding_and_mask_with_return(pair_ids)\n",
    "        pair_ids_padding_tensor = torch.tensor(pair_ids_padding_list).cuda()\n",
    "        pair_mask_tensor = torch.tensor(pair_mask_list).cuda()\n",
    "\n",
    "        _,global_att_mask=self.padding_and_mask_to_max_lenth([argument_ids],max_len)\n",
    "        global_att_mask_tensor=torch.tensor(global_att_mask).cuda()\n",
    "\n",
    "        try:\n",
    "\n",
    "            longformer_outputs = self.longformer(pair_ids_padding_tensor,\n",
    "                                                 attention_mask=pair_mask_tensor,global_attention_mask=global_att_mask_tensor) \n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "        last_hidden_state = longformer_outputs[0] \n",
    "\n",
    "        last_hidden_state_for_s = last_hidden_state[:, (argument_length+1):-1, :]\n",
    "\n",
    "        sen_emb_list = []\n",
    "        start_index = 0\n",
    "        end_index = 0\n",
    "        for i in range(0, len(sent_length_list)):\n",
    "            end_index = start_index + sent_length_list[i]\n",
    "            last_h_temp = last_hidden_state_for_s[:, start_index:end_index, :]\n",
    "            sen_emb_list.append(last_h_temp.mean(dim=-2))\n",
    "            start_index = end_index\n",
    "\n",
    "        sent_emb = torch.cat(sen_emb_list, dim=0)\n",
    "\n",
    "        sent_emb = self.dropout(sent_emb) \n",
    "        return sent_emb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def am_tagging_span_for_task1(self, para_tokens_list, mode):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sent_num_list = [len(para) for para in para_tokens_list]\n",
    "        sent_emb = self.bert_emb_for_task1(para_tokens_list) \n",
    "\n",
    "        para_emb = torch.split(sent_emb, sent_num_list, 0)\n",
    "\n",
    "        para_emb_packed = pack_sequence(para_emb, enforce_sorted=False)\n",
    "        para_lstm_out_packed, (h, c) = self.am_bilstm(para_emb_packed)\n",
    "        para_lstm_out_padded, _ = pad_packed_sequence(para_lstm_out_packed, batch_first=True)  \n",
    "\n",
    "\n",
    "        para_lstm_out = para_lstm_out_padded\n",
    "        batch_size, seq_len, hid_size = para_lstm_out.size()\n",
    "\n",
    "        start_logits = self.start_outputs(para_lstm_out).squeeze(\n",
    "            -1)  \n",
    "        end_logits = self.end_outputs(para_lstm_out).squeeze(-1)  \n",
    "\n",
    "        start_extend = para_lstm_out.unsqueeze(2).expand(-1, -1, seq_len, -1)\n",
    "\n",
    "        end_extend = para_lstm_out.unsqueeze(1).expand(-1, seq_len, -1, -1)\n",
    "\n",
    "        span_matrix = torch.cat([start_extend, end_extend], 3)\n",
    "\n",
    "\n",
    "        span_logits = self.span_embedding(span_matrix).squeeze(-1) \n",
    "\n",
    "\n",
    "\n",
    "        return start_logits,end_logits,span_logits\n",
    "\n",
    "    def am_tagging_span_for_task2(self, rev_para_tokens_list,rep_para_tokens_list, arg_pair_sems_list,mode='train'):\n",
    "\n",
    "\n",
    "        sent_num_list = [len(para) for para in rep_para_tokens_list]\n",
    "\n",
    "        arg_num_list = []\n",
    "\n",
    "\n",
    "        temp_arg_list = []\n",
    "        for batch_i, pred_arguments_labeldict in enumerate(arg_pair_sems_list):  \n",
    "            for rev_arg_span, label_dict in pred_arguments_labeldict.items():\n",
    "\n",
    "\n",
    "\n",
    "                temp_argu_o = rev_para_tokens_list[batch_i][rev_arg_span[0]:rev_arg_span[1] + 1] \n",
    "                temp_arg_list.append(temp_argu_o)\n",
    "                arg_num_list.append(sent_num_list[0])\n",
    "\n",
    "        para_lstm_out_list = []\n",
    "\n",
    "        for arg in temp_arg_list:\n",
    "            sent_emb = self.bert_emb_for_task2(rep_para_tokens_list, arg)\n",
    "            para_emb = torch.split(sent_emb, sent_num_list, 0)\n",
    "            para_emb_packed = pack_sequence(para_emb, enforce_sorted=False)\n",
    "\n",
    "            para_lstm_out_packed, (h, c) = self.am_bilstm(para_emb_packed)\n",
    "            para_lstm_out_padded, _ = pad_packed_sequence(para_lstm_out_packed, batch_first=True)\n",
    "            para_lstm_out_list.append(para_lstm_out_padded)\n",
    "\n",
    "        try:\n",
    "            lstm_out_cat = torch.cat(para_lstm_out_list, dim=0)\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "        para_lstm_out = lstm_out_cat \n",
    "        batch_size, seq_len, hid_size = para_lstm_out.size()\n",
    "\n",
    "\n",
    "        start_logits = self.start_outputs(para_lstm_out).squeeze(\n",
    "            -1) \n",
    "        end_logits = self.end_outputs(para_lstm_out).squeeze(-1) \n",
    "\n",
    "        start_extend = para_lstm_out.unsqueeze(2).expand(-1, -1, seq_len, -1)\n",
    "\n",
    "        end_extend = para_lstm_out.unsqueeze(1).expand(-1, seq_len, -1, -1)\n",
    "\n",
    "        span_matrix = torch.cat([start_extend, end_extend], 3)\n",
    "\n",
    "        span_logits = self.span_embedding(span_matrix).squeeze(-1) \n",
    "        return start_logits, end_logits, span_logits\n",
    "\n",
    "\n",
    "    def am_tagging_with_task1_for_task2(self, rev_para_tokens_list, rep_para_tokens_list, arg_list_from_task1,\n",
    "                              mode='train'):\n",
    "\n",
    "        sent_num_list = [len(para) for para in rep_para_tokens_list]\n",
    "\n",
    "        arg_num_list = []\n",
    "\n",
    "        temp_arg_list = []\n",
    "        for batch_i, pred_arguments in enumerate(arg_list_from_task1):\n",
    "            for rev_arg_span in pred_arguments:\n",
    "                temp_argu_o = rev_para_tokens_list[0][rev_arg_span[0]:rev_arg_span[1] + 1] \n",
    "                temp_arg_list.append(temp_argu_o) \n",
    "\n",
    "                arg_num_list.append(sent_num_list[0]) \n",
    "\n",
    "        para_lstm_out_list = []\n",
    "\n",
    "        for arg in temp_arg_list:\n",
    "            sent_emb = self.bert_emb_for_task2(rep_para_tokens_list, arg)\n",
    "\n",
    "            para_emb = torch.split(sent_emb, sent_num_list, 0)\n",
    "            para_emb_packed = pack_sequence(para_emb, enforce_sorted=False)\n",
    "\n",
    "            para_lstm_out_packed, (h, c) = self.am_bilstm(para_emb_packed)\n",
    "            para_lstm_out_padded, _ = pad_packed_sequence(para_lstm_out_packed, batch_first=True)\n",
    "            para_lstm_out_list.append(para_lstm_out_padded)\n",
    "\n",
    "        try:\n",
    "            lstm_out_cat = torch.cat(para_lstm_out_list, dim=0)\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "        para_lstm_out = lstm_out_cat \n",
    "        batch_size, seq_len, hid_size = para_lstm_out.size()\n",
    "\n",
    "        start_logits = self.start_outputs(para_lstm_out).squeeze(\n",
    "            -1) \n",
    "        end_logits = self.end_outputs(para_lstm_out).squeeze(-1)\n",
    "\n",
    "        start_extend = para_lstm_out.unsqueeze(2).expand(-1, -1, seq_len, -1)\n",
    "\n",
    "        end_extend = para_lstm_out.unsqueeze(1).expand(-1, seq_len, -1, -1)\n",
    "\n",
    "        span_matrix = torch.cat([start_extend, end_extend], 3)\n",
    "\n",
    "        span_logits = self.span_embedding(span_matrix).squeeze(-1) \n",
    "\n",
    "        return start_logits, end_logits, span_logits \n",
    "\n",
    "    def forward(self, para_tokens_list_o,para_tokens_list_for_2_o,rr_arg_pair_list_o,\n",
    "                     match_labels_o, start_labels_o, end_labels_o,tag_list_o):\n",
    "\n",
    "        total_loss_all=0\n",
    "\n",
    "        for para_tokens,para_tokens_2,rr_arg_pair,tag ,start_labels,end_labels,match_labels in zip(para_tokens_list_o,para_tokens_list_for_2_o,rr_arg_pair_list_o,tag_list_o,start_labels_o,end_labels_o,match_labels_o):\n",
    "\n",
    "            para_tokens_list=[para_tokens]\n",
    "            para_tokens_list_for_2=[para_tokens_2]\n",
    "            rr_arg_pair_list=[rr_arg_pair]\n",
    "\n",
    "\n",
    "\n",
    "            if tag==\"task1_review\" or tag==\"task1_reply\":\n",
    "\n",
    "                start_logits, end_logits, span_logits= self.am_tagging_span_for_task1(para_tokens_list,mode=\"train\")\n",
    "\n",
    "            elif tag==\"task2_review\" :\n",
    "                # review\n",
    "                start_logits, end_logits, span_logits\\\n",
    "                    = self.am_tagging_span_for_task2(para_tokens_list,para_tokens_list_for_2,rr_arg_pair_list,mode=\"train\")\n",
    "\n",
    "            elif tag == \"task2_reply\":\n",
    "                start_logits, end_logits, span_logits \\\n",
    "                    = self.am_tagging_span_for_task2(para_tokens_list_for_2, para_tokens_list, rr_arg_pair_list,mode=\"train\")\n",
    "\n",
    "\n",
    "            start_loss, end_loss, match_loss = self.compute_loss(start_logits,\n",
    "                                                                 end_logits, span_logits,\n",
    "                                                                 start_labels.expand(1,\n",
    "                                                                                        -1).cuda(),\n",
    "                                                                 end_labels.expand(1,\n",
    "                                                                                      -1).cuda(),\n",
    "                                                                 match_labels.expand(1, -1,\n",
    "                                                                                        -1).cuda())\n",
    "            total_loss = self.weight_start * start_loss + self.weight_end * end_loss + self.weight_span * match_loss\n",
    "\n",
    "            total_loss_all=total_loss_all+total_loss\n",
    "\n",
    "\n",
    "\n",
    "        total_loss_all_pingjun=total_loss_all/len(para_tokens_list_o)\n",
    "\n",
    "        return total_loss_all_pingjun\n",
    "\n",
    "    def predict_span(self, review_para_tokens_list, review_tags_list,\n",
    "\n",
    "                     reply_para_tokens_list, reply_tags_list):\n",
    "\n",
    "\n",
    "        # review\n",
    "        review_start_logits, review_end_logits, review_span_logits = self.am_tagging_span_for_task1(\n",
    "            review_para_tokens_list,\n",
    "             mode=\"test\")\n",
    "        review_start_preds, review_end_preds, review_span_preds = F.sigmoid(review_start_logits) > 0.5, F.sigmoid(\n",
    "            review_end_logits) > 0.5, F.sigmoid(review_span_logits) > 0.5\n",
    "\n",
    "        pred_rev_args_dict = {}\n",
    "        pred_rev_args_dict['review_start_preds'] = review_start_preds\n",
    "        pred_rev_args_dict['review_end_preds'] = review_end_preds\n",
    "        pred_rev_args_dict['review_span_preds'] = review_span_preds\n",
    "\n",
    "        # reply\n",
    "        reply_start_logits, reply_end_logits, reply_span_logits = self.am_tagging_span_for_task1(reply_para_tokens_list,\n",
    "\n",
    "                                                                                                 mode=\"test\")\n",
    "\n",
    "        reply_start_preds, reply_end_preds, reply_span_preds = F.sigmoid(reply_start_logits) > 0.5, F.sigmoid(\n",
    "            reply_end_logits) > 0.5, F.sigmoid(reply_span_logits) > 0.5\n",
    "\n",
    "        pred_rep_args_dict = {}\n",
    "        pred_rep_args_dict['reply_start_preds'] = reply_start_preds\n",
    "        pred_rep_args_dict['reply_end_preds'] = reply_end_preds\n",
    "        pred_rep_args_dict['reply_span_preds'] = reply_span_preds\n",
    "\n",
    "        pred_rev_args_list = extract_span_arguments_yi(pred_rev_args_dict['review_span_preds'],\n",
    "                                                       pred_rev_args_dict['review_start_preds'],\n",
    "                                                       pred_rev_args_dict['review_end_preds'])\n",
    "        pred_rep_args_list = extract_span_arguments_yi(pred_rep_args_dict['reply_span_preds'],\n",
    "                                                       pred_rep_args_dict['reply_start_preds'],\n",
    "                                                       pred_rep_args_dict['reply_end_preds'])\n",
    "\n",
    "        test_rev_args_list = []\n",
    "\n",
    "        for iitem in pred_rev_args_list:\n",
    "            for arg in iitem:\n",
    "                test_rev_args_list.append(arg)\n",
    "        if test_rev_args_list == []:\n",
    "            pred_args_pair_dict_list = [{} for t in pred_rev_args_list]\n",
    "        else:\n",
    "            try:\n",
    "                # review\n",
    "                review_start_logits, review_end_logits, review_span_logits \\\n",
    "                    = self.am_tagging_with_task1_for_task2(review_para_tokens_list, reply_para_tokens_list,\n",
    "                                                           pred_rev_args_list, mode=\"test\")\n",
    "\n",
    "                review_start_preds, review_end_preds, review_span_preds = F.sigmoid(\n",
    "                    review_start_logits) > 0.5, F.sigmoid(\n",
    "                    review_end_logits) > 0.5, F.sigmoid(review_span_logits) > 0.5\n",
    "\n",
    "            except:\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "            review_span_preds_list = [i for i in review_span_preds]\n",
    "            review_start_preds_list = [i for i in review_start_preds]\n",
    "            review_end_preds_list = [i for i in review_end_preds]\n",
    "\n",
    "            pred_pair_rep_args_list = extract_span_arguments_yi(review_span_preds_list, review_start_preds_list,\n",
    "                                                                review_end_preds_list)\n",
    "\n",
    "            # true_rev_args_list = extract_arguments(review_tags_list)\n",
    "            pred_args_pair_dict_list = []\n",
    "            i = 0\n",
    "            for true_arguments in pred_rev_args_list:\n",
    "                pred_args_pair_dict = {}\n",
    "                for args in true_arguments:\n",
    "                    pred_args_pair_dict[args] = (pred_pair_rep_args_list[i], \\\n",
    "                                                 [1] * len(pred_pair_rep_args_list[i]))\n",
    "                    i += 1\n",
    "                pred_args_pair_dict_list.append(pred_args_pair_dict)\n",
    "\n",
    "        # reply\n",
    "        test_rep_args_list = []\n",
    "        # true_rep_args_list = extract_arguments(reply_tags_list)\n",
    "        for iitem in pred_rep_args_list:\n",
    "            for arg in iitem:\n",
    "                test_rep_args_list.append(arg)\n",
    "        if test_rep_args_list == []:\n",
    "            pred_args_pair_dict_2_list = [{} for t in pred_rep_args_list]\n",
    "        else:\n",
    "            try:\n",
    "                # reply\n",
    "                reply_start_logits, reply_end_logits, reply_span_logits = self.am_tagging_with_task1_for_task2(\n",
    "                    reply_para_tokens_list, review_para_tokens_list, pred_rep_args_list,\n",
    "                    mode=\"test\")\n",
    "\n",
    "                # reply_start_preds, reply_end_preds, reply_span_preds = reply_start_logits > 0, reply_end_logits > 0, reply_span_logits > 0\n",
    "                reply_start_preds, reply_end_preds, reply_span_preds = F.sigmoid(reply_start_logits) > 0.5, F.sigmoid(\n",
    "                    reply_end_logits) > 0.5, F.sigmoid(reply_span_logits) > 0.5\n",
    "\n",
    "\n",
    "            except:\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "            rebuttal_span_preds_list = [i for i in reply_span_preds]\n",
    "            rebuttal_start_preds_list = [i for i in reply_start_preds]\n",
    "            rebuttal_end_preds_list = [i for i in reply_end_preds]\n",
    "\n",
    "            pred_pair_rev_args_list = extract_span_arguments_yi(rebuttal_span_preds_list, rebuttal_start_preds_list,\n",
    "                                                                rebuttal_end_preds_list)\n",
    "\n",
    "            pred_args_pair_dict_2_list = []\n",
    "            i = 0\n",
    "            for true_arguments in pred_rep_args_list:\n",
    "                pred_args_pair_dict = {}\n",
    "                for args in true_arguments:\n",
    "                    pred_args_pair_dict[args] = (pred_pair_rev_args_list[i], \\\n",
    "                                                 [1] * len(pred_pair_rev_args_list[i]))\n",
    "                    i += 1\n",
    "                pred_args_pair_dict_2_list.append(pred_args_pair_dict)\n",
    "\n",
    "        return pred_rev_args_dict, pred_rep_args_dict, pred_args_pair_dict_list, pred_args_pair_dict_2_list\n",
    "\n",
    "    def predict_span_for_task1(self, review_para_tokens_list, review_tags_list,\n",
    "\n",
    "                     reply_para_tokens_list, reply_tags_list):\n",
    "\n",
    "        # evaluate for task1:\n",
    "\n",
    "        # review\n",
    "        review_start_logits, review_end_logits, review_span_logits = self.am_tagging_span_for_task1(\n",
    "            review_para_tokens_list,\n",
    "             mode=\"test\")\n",
    "\n",
    "        review_start_preds, review_end_preds, review_span_preds = F.sigmoid(review_start_logits) > 0.5, F.sigmoid(\n",
    "            review_end_logits) > 0.5, F.sigmoid(review_span_logits) > 0.5\n",
    "\n",
    "        pred_rev_args_dict = {}\n",
    "        pred_rev_args_dict['review_start_preds'] = review_start_preds\n",
    "        pred_rev_args_dict['review_end_preds'] = review_end_preds\n",
    "        pred_rev_args_dict['review_span_preds'] = review_span_preds\n",
    "\n",
    "        # reply\n",
    "        reply_start_logits, reply_end_logits, reply_span_logits = self.am_tagging_span_for_task1(reply_para_tokens_list,\n",
    "\n",
    "                                                                                                 mode=\"test\")\n",
    "        reply_start_preds, reply_end_preds, reply_span_preds = F.sigmoid(reply_start_logits) > 0.5, F.sigmoid(\n",
    "            reply_end_logits) > 0.5, F.sigmoid(reply_span_logits) > 0.5\n",
    "\n",
    "        pred_rep_args_dict = {}\n",
    "        pred_rep_args_dict['reply_start_preds'] = reply_start_preds\n",
    "        pred_rep_args_dict['reply_end_preds'] = reply_end_preds\n",
    "        pred_rep_args_dict['reply_span_preds'] = reply_span_preds\n",
    "\n",
    "\n",
    "        return pred_rev_args_dict, pred_rep_args_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def padding_and_mask(self, ids_list):\n",
    "        max_len = max([len(x) for x in ids_list])\n",
    "        mask_list = []\n",
    "        ids_padding_list = []\n",
    "        for ids in ids_list:\n",
    "            mask = [1.] * len(ids) + [0.] * (max_len - len(ids))\n",
    "            ids = ids + [0] * (max_len - len(ids))\n",
    "            mask_list.append(mask)\n",
    "            ids_padding_list.append(ids)\n",
    "        return ids_padding_list, mask_list\n",
    "    def padding_and_mask_with_return(self, ids_list):\n",
    "        max_len = max([len(x) for x in ids_list])\n",
    "        mask_list = []\n",
    "        ids_padding_list = []\n",
    "        for ids in ids_list:\n",
    "            mask = [1.] * len(ids) + [0.] * (max_len - len(ids))\n",
    "            ids = ids + [0] * (max_len - len(ids))\n",
    "            mask_list.append(mask)\n",
    "            ids_padding_list.append(ids)\n",
    "        return ids_padding_list, mask_list,max_len\n",
    "\n",
    "    def padding_and_mask_to_max_lenth(self, ids_list,max_len):\n",
    "        mask_list = []\n",
    "        ids_padding_list = []\n",
    "        for ids in ids_list:\n",
    "\n",
    "            mask = [1.] * len(ids) +[0.] * (max_len - len(ids)) \n",
    "            ids = ids + [0] * (max_len - len(ids))\n",
    "            mask_list.append(mask)\n",
    "            ids_padding_list.append(ids)\n",
    "        return ids_padding_list, mask_list\n",
    "\n",
    "\n",
    "    def padding_matrix(self, matrix_tensor_list):\n",
    "        seq_list=[]\n",
    "        for matrix in matrix_tensor_list:\n",
    "            seq=matrix.size()[0]\n",
    "            seq_list.append(seq)\n",
    "\n",
    "        max_seq_len = max(seq_list)\n",
    "\n",
    "        new_matrix_list=[]\n",
    "        for matrix in matrix_tensor_list:\n",
    "            seq=matrix.size()[0]\n",
    "\n",
    "            if seq<max_seq_len:\n",
    "\n",
    "                o_t_list=torch.split(matrix,1,dim=0)\n",
    "                p_o_t_list=[t[0] for t in o_t_list]\n",
    "                left_num=max_seq_len-seq\n",
    "\n",
    "                for i in range(left_num):\n",
    "                    p_o_t_list.append(torch.zeros(max_seq_len,dtype=torch.long))\n",
    "\n",
    "                new_matrix=pad_sequence(p_o_t_list,batch_first=True)\n",
    "                new_matrix_list.append(new_matrix)\n",
    "\n",
    "            else:\n",
    "                new_matrix_list.append(matrix)\n",
    "\n",
    "        padded_matrix=torch.stack(new_matrix_list)\n",
    "        return padded_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9db6b-cc38-4da9-942d-cc21fa8e27ad",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec0ba68-586f-4922-8ea3-1c3cfb3cd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags2id = {'O': 0, 'B-Review': 1, 'I-Review': 2, 'E-Review': 3, 'S-Review': 4,\n",
    "           'B-Reply': 1, 'I-Reply': 2, 'E-Reply': 3, 'S-Reply': 4,\n",
    "           'B': 1, 'I': 2, 'E': 3, 'S': 4}\n",
    "\n",
    "def load_data_new_sample(file_path):\n",
    "\n",
    "    sample_list_task1_for_review = []\n",
    "    sample_list_task1_for_reply = []\n",
    "    sample_list_task2_for_review_dir = []\n",
    "    sample_list_task2_for_reply_dir = []\n",
    "\n",
    "    with open(file_path, 'r') as fp:\n",
    "        rr_pair_list = fp.read().split('\\n\\n\\n')\n",
    "        for rr_pair in rr_pair_list:\n",
    "            if rr_pair == '':\n",
    "                continue\n",
    "            review, reply = rr_pair.split('\\n\\n')\n",
    "\n",
    "            sample_review = {'sentences': [], 'bio_tags': [],\n",
    "                             'pair_tags': [], 'text_type': None, 'sub_ids': [], 'arg_spans': []}\n",
    "            for line in review.strip().split('\\n'):\n",
    "                sent, bio_tag, pair_tag, text_type, sub_id = line.strip().split('\\t')\n",
    "                sample_review['sentences'].append(sent)\n",
    "                sample_review['bio_tags'].append(bio_tag)\n",
    "                sample_review['pair_tags'].append(pair_tag)\n",
    "                sample_review['text_type'] = text_type\n",
    "                sample_review['sub_ids'] = sub_id\n",
    "            tags_ids = [tags2id[t] for t in sample_review['bio_tags']]\n",
    "\n",
    "            review_spans=get_arg_span(tags_ids)\n",
    "\n",
    "            sample_review['arg_spans'] = review_spans\n",
    "\n",
    "            seq_len = len(tags_ids)\n",
    "\n",
    "            review_start_positions = []\n",
    "            review_end_positions = []\n",
    "            match_labels = torch.zeros([seq_len, seq_len], dtype=torch.long)\n",
    "            for start, end in review_spans:\n",
    "                review_start_positions.append(start)\n",
    "                review_end_positions.append(end)\n",
    "                if start >= seq_len or end >= seq_len:\n",
    "                    continue\n",
    "                match_labels[start, end] = 1\n",
    "\n",
    "            start_labels = torch.LongTensor([(1 if idx in review_start_positions else 0) for idx in range(\n",
    "                seq_len)]) \n",
    "            end_labels = torch.LongTensor([(1 if idx in review_end_positions else 0) for idx in range(\n",
    "                seq_len)])  \n",
    "            sample_review['match_labels'] = match_labels\n",
    "            sample_review['start_labels'] = start_labels\n",
    "            sample_review['end_labels'] = end_labels\n",
    "\n",
    "            sample_review['tag']=\"task1_review\"\n",
    "\n",
    "            sample_list_task1_for_review.append(sample_review)\n",
    "\n",
    "            sample_reply = {'sentences': [], 'bio_tags': [],\n",
    "                            'pair_tags': [], 'text_type': None, 'sub_ids': [], 'arg_spans': []}\n",
    "            for line in reply.strip().split('\\n'):\n",
    "                sent, bio_tag, pair_tag, text_type, sub_id = line.strip().split('\\t')\n",
    "                sample_reply['sentences'].append(sent)\n",
    "                sample_reply['bio_tags'].append(bio_tag)\n",
    "                sample_reply['pair_tags'].append(pair_tag)\n",
    "                sample_reply['text_type'] = text_type\n",
    "                sample_reply['sub_ids'] = sub_id\n",
    "            tags_ids = [tags2id[t] for t in sample_reply['bio_tags']]\n",
    "\n",
    "\n",
    "            reply_spans = get_arg_span(tags_ids)\n",
    "\n",
    "            sample_reply['arg_spans'] = reply_spans\n",
    "\n",
    "            seq_len = len(tags_ids)\n",
    "\n",
    "            reply_start_positions = []\n",
    "            reply_end_positions = []\n",
    "            match_labels = torch.zeros([seq_len, seq_len], dtype=torch.long)\n",
    "            for start, end in reply_spans:\n",
    "                reply_start_positions.append(start)\n",
    "                reply_end_positions.append(end)\n",
    "                if start >= seq_len or end >= seq_len:\n",
    "                    continue\n",
    "                match_labels[start, end] = 1\n",
    "\n",
    "            start_labels = torch.LongTensor([(1 if idx in reply_start_positions else 0) for idx in\n",
    "                                             range(\n",
    "                                                 seq_len)])\n",
    "            end_labels = torch.LongTensor([(1 if idx in reply_end_positions else 0) for idx in\n",
    "                                           range(\n",
    "                                               seq_len)]) \n",
    "\n",
    "            sample_reply['match_labels'] = match_labels\n",
    "            sample_reply['start_labels'] = start_labels\n",
    "            sample_reply['end_labels'] = end_labels\n",
    "\n",
    "\n",
    "            sample_reply['tag'] = \"task1_reply\"\n",
    "            sample_list_task1_for_reply.append(sample_reply)\n",
    "\n",
    "            rev_arg_2_rep_arg_dict = {}\n",
    "            for rev_arg_span in sample_review['arg_spans']:\n",
    "                rev_arg_pair_id = int(sample_review['pair_tags'][rev_arg_span[0]].split('-')[-1])\n",
    "                rev_arg_2_rep_arg_dict[rev_arg_span] = []\n",
    "                for rep_arg_span in sample_reply['arg_spans']:\n",
    "                    rep_arg_pair_id = int(sample_reply['pair_tags'][rep_arg_span[0]].split('-')[-1])\n",
    "                    if rev_arg_pair_id == rep_arg_pair_id:\n",
    "                        rev_arg_2_rep_arg_dict[rev_arg_span].append(rep_arg_span)\n",
    "            sample_review['rev_arg_2_rep_arg_dict'] = rev_arg_2_rep_arg_dict\n",
    "\n",
    "\n",
    "            rep_seq_len = len(sample_reply['bio_tags'])\n",
    "\n",
    "\n",
    "\n",
    "            for rev_arg_span, rep_arg_spans in rev_arg_2_rep_arg_dict.items():\n",
    "\n",
    "                pair_reply_start_positions = []\n",
    "                pair_reply_end_positions = []\n",
    "                pair_match_labels = torch.zeros([rep_seq_len, rep_seq_len], dtype=torch.long)\n",
    "                for start, end in rep_arg_spans:\n",
    "                    pair_reply_start_positions.append(start)\n",
    "                    pair_reply_end_positions.append(end)\n",
    "                    if start >= rep_seq_len or end >= rep_seq_len:\n",
    "                        continue\n",
    "                    pair_match_labels[start, end] = 1\n",
    "\n",
    "                pair_start_labels = torch.LongTensor([(1 if idx in pair_reply_start_positions else 0) for idx in range(rep_seq_len)])\n",
    "                pair_end_labels = torch.LongTensor([(1 if idx in pair_reply_end_positions else 0) for idx in range(rep_seq_len)])\n",
    "\n",
    "\n",
    "                sample_review_dir_temp={}\n",
    "                sample_review_dir_temp['review_sentences']=sample_review['sentences']\n",
    "                sample_review_dir_temp['reply_sentences'] = sample_reply['sentences']\n",
    "                sample_review_dir_temp['match_labels']=pair_match_labels\n",
    "                sample_review_dir_temp['start_labels'] = pair_start_labels\n",
    "                sample_review_dir_temp['end_labels'] = pair_end_labels\n",
    "\n",
    "                sample_review_dir_temp['tag'] =\"task2_review\"\n",
    "\n",
    "                temp_rr_dict={}\n",
    "                tags = spans_to_tags(rep_arg_spans, rep_seq_len)\n",
    "                temp_rr_dict[rev_arg_span] = tags\n",
    "                sample_review_dir_temp['rr_arg_dict']=temp_rr_dict\n",
    "\n",
    "                sample_list_task2_for_review_dir.append(sample_review_dir_temp)\n",
    "\n",
    "            rep_arg_2_rev_arg_dict = {}\n",
    "\n",
    "\n",
    "            for rep_arg_span in sample_reply['arg_spans']:\n",
    "                rep_arg_pair_id = int(sample_reply['pair_tags'][rep_arg_span[0]].split('-')[-1])\n",
    "                rep_arg_2_rev_arg_dict[rep_arg_span] = []\n",
    "                for rev_arg_span in sample_review['arg_spans']:\n",
    "                    rev_arg_pair_id = int(sample_review['pair_tags'][rev_arg_span[0]].split('-')[-1])\n",
    "                    if rep_arg_pair_id == rev_arg_pair_id:\n",
    "                        rep_arg_2_rev_arg_dict[rep_arg_span].append(rev_arg_span)\n",
    "            sample_reply['rep_arg_2_rev_arg_dict'] = rep_arg_2_rev_arg_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            rev_seq_len = len(sample_review['bio_tags'])\n",
    "\n",
    "\n",
    "            for rep_arg_span, rev_arg_spans in rep_arg_2_rev_arg_dict.items():\n",
    "\n",
    "                pair_review_start_positions = []\n",
    "                pair_review_end_positions = []\n",
    "                pair_match_labels = torch.zeros([rev_seq_len, rev_seq_len], dtype=torch.long)\n",
    "                for start, end in rev_arg_spans:\n",
    "                    pair_review_start_positions.append(start)\n",
    "                    pair_review_end_positions.append(end)\n",
    "                    if start >= rev_seq_len or end >= rev_seq_len:\n",
    "                        continue\n",
    "                    pair_match_labels[start, end] = 1\n",
    "\n",
    "                pair_start_labels = torch.LongTensor([(1 if idx in pair_review_start_positions else 0) for idx in range( rev_seq_len)])\n",
    "                pair_end_labels = torch.LongTensor([(1 if idx in pair_review_end_positions else 0) for idx in range(rev_seq_len)])\n",
    "\n",
    "\n",
    "                sample_reply_dir_temp = {}\n",
    "                sample_reply_dir_temp['review_sentences'] = sample_review['sentences']\n",
    "                sample_reply_dir_temp['reply_sentences'] = sample_reply['sentences']\n",
    "                sample_reply_dir_temp['match_labels'] = pair_match_labels\n",
    "                sample_reply_dir_temp['start_labels'] = pair_start_labels\n",
    "                sample_reply_dir_temp['end_labels'] = pair_end_labels\n",
    "\n",
    "                sample_reply_dir_temp['tag'] = \"task2_reply\"\n",
    "\n",
    "                temp_rr_dict = {}\n",
    "                tags = spans_to_tags(rev_arg_spans, rev_seq_len)\n",
    "                temp_rr_dict[rep_arg_span] = tags\n",
    "                sample_reply_dir_temp['rr_arg_dict']= temp_rr_dict\n",
    "\n",
    "\n",
    "                sample_list_task2_for_reply_dir.append(sample_reply_dir_temp)\n",
    "\n",
    "    return sample_list_task1_for_review,sample_list_task1_for_reply,sample_list_task2_for_review_dir,sample_list_task2_for_reply_dir\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    sample_list = []\n",
    "    with open(file_path, 'r') as fp:\n",
    "        rr_pair_list = fp.read().split('\\n\\n\\n')\n",
    "        for rr_pair in rr_pair_list:\n",
    "            if rr_pair == '':\n",
    "                continue\n",
    "            review, reply = rr_pair.split('\\n\\n')\n",
    "\n",
    "            sample_review = {'sentences': [], 'bio_tags': [],\n",
    "                             'pair_tags': [], 'text_type': None, 'sub_ids': [], 'arg_spans': []}\n",
    "            for line in review.strip().split('\\n'):\n",
    "                sent, bio_tag, pair_tag, text_type, sub_id = line.strip().split('\\t')\n",
    "                sample_review['sentences'].append(sent)\n",
    "                sample_review['bio_tags'].append(bio_tag)\n",
    "                sample_review['pair_tags'].append(pair_tag)\n",
    "                sample_review['text_type'] = text_type\n",
    "                sample_review['sub_ids'] = sub_id\n",
    "            tags_ids = [tags2id[t] for t in sample_review['bio_tags']]\n",
    "\n",
    "            review_spans=get_arg_span(tags_ids)\n",
    "\n",
    "            sample_review['arg_spans'] = review_spans\n",
    "\n",
    "            seq_len = len(tags_ids)\n",
    "\n",
    "            review_start_positions = []\n",
    "            review_end_positions = []\n",
    "            match_labels = torch.zeros([seq_len, seq_len], dtype=torch.long)\n",
    "            for start, end in review_spans:\n",
    "                review_start_positions.append(start)\n",
    "                review_end_positions.append(end)\n",
    "                if start >= seq_len or end >= seq_len:\n",
    "                    continue\n",
    "                match_labels[start, end] = 1\n",
    "\n",
    "            start_labels = torch.LongTensor([(1 if idx in review_start_positions else 0) for idx in range(\n",
    "                seq_len)])  \n",
    "            end_labels = torch.LongTensor([(1 if idx in review_end_positions else 0) for idx in range(\n",
    "                seq_len)])  \n",
    "            sample_review['match_labels'] = match_labels\n",
    "            sample_review['start_labels'] = start_labels\n",
    "            sample_review['end_labels'] = end_labels\n",
    "\n",
    "            sample_reply = {'sentences': [], 'bio_tags': [],\n",
    "                            'pair_tags': [], 'text_type': None, 'sub_ids': [], 'arg_spans': []}\n",
    "            for line in reply.strip().split('\\n'):\n",
    "                sent, bio_tag, pair_tag, text_type, sub_id = line.strip().split('\\t')\n",
    "                sample_reply['sentences'].append(sent)\n",
    "                sample_reply['bio_tags'].append(bio_tag)\n",
    "                sample_reply['pair_tags'].append(pair_tag)\n",
    "                sample_reply['text_type'] = text_type\n",
    "                sample_reply['sub_ids'] = sub_id\n",
    "            tags_ids = [tags2id[t] for t in sample_reply['bio_tags']]\n",
    "\n",
    "\n",
    "            reply_spans = get_arg_span(tags_ids)\n",
    "\n",
    "            sample_reply['arg_spans'] = reply_spans\n",
    "\n",
    "            seq_len = len(tags_ids)\n",
    "\n",
    "            reply_start_positions = []\n",
    "            reply_end_positions = []\n",
    "            match_labels = torch.zeros([seq_len, seq_len], dtype=torch.long)\n",
    "            for start, end in reply_spans:\n",
    "                reply_start_positions.append(start)\n",
    "                reply_end_positions.append(end)\n",
    "                if start >= seq_len or end >= seq_len:\n",
    "                    continue\n",
    "                match_labels[start, end] = 1\n",
    "\n",
    "            start_labels = torch.LongTensor([(1 if idx in reply_start_positions else 0) for idx in\n",
    "                                             range(\n",
    "                                                 seq_len)]) \n",
    "            end_labels = torch.LongTensor([(1 if idx in reply_end_positions else 0) for idx in\n",
    "                                           range(\n",
    "                                               seq_len)]) \n",
    "\n",
    "            sample_reply['match_labels'] = match_labels\n",
    "            sample_reply['start_labels'] = start_labels\n",
    "            sample_reply['end_labels'] = end_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            rev_arg_2_rep_arg_dict = {}\n",
    "            for rev_arg_span in sample_review['arg_spans']:\n",
    "                rev_arg_pair_id = int(sample_review['pair_tags'][rev_arg_span[0]].split('-')[-1])\n",
    "                rev_arg_2_rep_arg_dict[rev_arg_span] = []\n",
    "                for rep_arg_span in sample_reply['arg_spans']:\n",
    "                    rep_arg_pair_id = int(sample_reply['pair_tags'][rep_arg_span[0]].split('-')[-1])\n",
    "                    if rev_arg_pair_id == rep_arg_pair_id:\n",
    "                        rev_arg_2_rep_arg_dict[rev_arg_span].append(rep_arg_span)\n",
    "            sample_review['rev_arg_2_rep_arg_dict'] = rev_arg_2_rep_arg_dict\n",
    "\n",
    "\n",
    "            rep_seq_len = len(sample_reply['bio_tags'])\n",
    "\n",
    "            rev_arg_2_rep_arg_dict_sem = {}\n",
    "            for rev_arg_span, rep_arg_spans in rev_arg_2_rep_arg_dict.items():\n",
    "\n",
    "                pair_reply_start_positions = []\n",
    "                pair_reply_end_positions = []\n",
    "                pair_match_labels = torch.zeros([rep_seq_len, rep_seq_len], dtype=torch.long)\n",
    "                for start, end in rep_arg_spans:\n",
    "                    pair_reply_start_positions.append(start)\n",
    "                    pair_reply_end_positions.append(end)\n",
    "                    if start >= rep_seq_len or end >= rep_seq_len:\n",
    "                        continue\n",
    "                    pair_match_labels[start, end] = 1\n",
    "\n",
    "                pair_start_labels = torch.LongTensor([(1 if idx in pair_reply_start_positions else 0) for idx in range(rep_seq_len)])\n",
    "                pair_end_labels = torch.LongTensor([(1 if idx in pair_reply_end_positions else 0) for idx in range(rep_seq_len)])\n",
    "\n",
    "                temp_dict={}\n",
    "                temp_dict['match_labels'] = pair_match_labels\n",
    "                temp_dict['start_labels'] = pair_start_labels\n",
    "                temp_dict['end_labels'] = pair_end_labels\n",
    "\n",
    "                rev_arg_2_rep_arg_dict_sem[rev_arg_span] =temp_dict\n",
    "\n",
    "            sample_review['rev_arg_2_rep_arg_dict_sem'] = rev_arg_2_rep_arg_dict_sem\n",
    "\n",
    "\n",
    "            rev_arg_2_rep_arg_tags_dict = {}\n",
    "            for rev_arg_span, rep_arg_spans in rev_arg_2_rep_arg_dict.items():\n",
    "                tags = spans_to_tags(rep_arg_spans, rep_seq_len)\n",
    "                rev_arg_2_rep_arg_tags_dict[rev_arg_span] = tags\n",
    "            sample_review['rev_arg_2_rep_arg_tags_dict'] = rev_arg_2_rep_arg_tags_dict\n",
    "\n",
    "            rep_arg_2_rev_arg_dict = {}\n",
    "            for rep_arg_span in sample_reply['arg_spans']:\n",
    "                rep_arg_pair_id = int(sample_reply['pair_tags'][rep_arg_span[0]].split('-')[-1])\n",
    "                rep_arg_2_rev_arg_dict[rep_arg_span] = []\n",
    "                for rev_arg_span in sample_review['arg_spans']:\n",
    "                    rev_arg_pair_id = int(sample_review['pair_tags'][rev_arg_span[0]].split('-')[-1])\n",
    "                    if rep_arg_pair_id == rev_arg_pair_id:\n",
    "                        rep_arg_2_rev_arg_dict[rep_arg_span].append(rev_arg_span)\n",
    "            sample_reply['rep_arg_2_rev_arg_dict'] = rep_arg_2_rev_arg_dict\n",
    "\n",
    "\n",
    "\n",
    "            rev_seq_len = len(sample_review['bio_tags'])\n",
    "\n",
    "            rep_arg_2_rev_arg_dict_sem={}\n",
    "            for rep_arg_span, rev_arg_spans in rep_arg_2_rev_arg_dict.items():\n",
    "\n",
    "                pair_review_start_positions = []\n",
    "                pair_review_end_positions = []\n",
    "                pair_match_labels = torch.zeros([rev_seq_len, rev_seq_len], dtype=torch.long)\n",
    "                for start, end in rev_arg_spans:\n",
    "                    pair_review_start_positions.append(start)\n",
    "                    pair_review_end_positions.append(end)\n",
    "                    if start >= rev_seq_len or end >= rev_seq_len:\n",
    "                        continue\n",
    "                    pair_match_labels[start, end] = 1\n",
    "\n",
    "                pair_start_labels = torch.LongTensor([(1 if idx in pair_review_start_positions else 0) for idx in range( rev_seq_len)])\n",
    "                pair_end_labels = torch.LongTensor([(1 if idx in pair_review_end_positions else 0) for idx in range(rev_seq_len)])\n",
    "\n",
    "                temp_dict={}\n",
    "                temp_dict['match_labels'] = pair_match_labels\n",
    "                temp_dict['start_labels'] = pair_start_labels\n",
    "                temp_dict['end_labels'] = pair_end_labels\n",
    "\n",
    "                rep_arg_2_rev_arg_dict_sem[rep_arg_span] = temp_dict\n",
    "            sample_reply['rep_arg_2_rev_arg_dict_sem'] = rep_arg_2_rev_arg_dict_sem\n",
    "\n",
    "\n",
    "            rep_arg_2_rev_arg_tags_dict = {}\n",
    "            for rep_arg_span, rev_arg_spans in rep_arg_2_rev_arg_dict.items():\n",
    "                tags = spans_to_tags(rev_arg_spans, rev_seq_len)\n",
    "                rep_arg_2_rev_arg_tags_dict[rep_arg_span] = tags\n",
    "            sample_reply['rep_arg_2_rev_arg_tags_dict'] = rep_arg_2_rev_arg_tags_dict\n",
    "\n",
    "            sample_list.append({'review': sample_review,\n",
    "                                'reply': sample_reply})\n",
    "    return sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857239e1-4b75-41a0-82e6-cdfce9b0a883",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100fa6bb-e20c-452b-a2f1-590bcdb87dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_metric(true_args_list, pred_args_list):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for true_args, pred_args in zip(true_args_list, pred_args_list):\n",
    "        true_args_set = set(true_args)\n",
    "        pred_args_set = set(pred_args)\n",
    "        assert len(true_args_set) == len(true_args)\n",
    "        assert len(pred_args_set) == len(pred_args)\n",
    "        tp += len(true_args_set & pred_args_set)\n",
    "        fp += len(pred_args_set - true_args_set)\n",
    "        fn += len(true_args_set - pred_args_set)\n",
    "    if tp + fp == 0:\n",
    "        pre = tp / (tp + fp + 1e-10)\n",
    "    else:\n",
    "        pre = tp / (tp + fp)\n",
    "    if tp + fn == 0:\n",
    "        rec = tp / (tp + fn + 1e-10)\n",
    "    else:\n",
    "        rec = tp / (tp + fn)\n",
    "    if pre == 0. and rec == 0.:\n",
    "        f1 = (2 * pre * rec) / (pre + rec + 1e-10)\n",
    "    else:\n",
    "        f1 = (2 * pre * rec) / (pre + rec)\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return {'pre': pre, 'rec': rec, 'f1': f1, 'acc': acc}\n",
    "\n",
    "\n",
    "def evaluate(model, data_list):\n",
    "    data_len = len(data_list)\n",
    "    model.eval()\n",
    "\n",
    "    all_true_rev_args_list = []\n",
    "    all_pred_rev_args_list = []\n",
    "    all_true_rep_args_list = []\n",
    "    all_pred_rep_args_list = []\n",
    "\n",
    "    all_true_arg_pairs_list = []\n",
    "\n",
    "    all_pred_arg_pairs_list = []\n",
    "    all_pred_arg_pairs_list_from_rev = []\n",
    "    all_pred_arg_pairs_list_from_rep = []\n",
    "\n",
    "\n",
    "    for batch_i in tqdm(range(data_len)):\n",
    "        data_batch = data_list[batch_i :(batch_i + 1) ]\n",
    "\n",
    "\n",
    "        review_para_tokens_list, review_tags_list = [], []\n",
    "        reply_para_tokens_list, reply_tags_list = [], []\n",
    "\n",
    "        review_match_labels, review_start_labels, review_end_labels = [], [], []\n",
    "        reply_match_labels, reply_start_labels, reply_end_labels = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rev_arg_2_rep_arg_sems_list = []\n",
    "        rep_arg_2_rev_arg_sems_list = []\n",
    "\n",
    "        true_arg_pairs_list = []\n",
    "\n",
    "\n",
    "        for sample in data_batch:\n",
    "\n",
    "            review_para_tokens_list.append(sample['review']['sentences'])\n",
    "            tags_ids = [tags2id[tag] for tag in sample['review']['bio_tags']]\n",
    "            review_tags_list.append(tags_ids)\n",
    "            # review for task1\n",
    "            review_match_labels.append(sample['review']['match_labels'])\n",
    "            review_start_labels.append(sample['review']['start_labels'])\n",
    "            review_end_labels.append(sample['review']['end_labels'])\n",
    "            # review for task2\n",
    "\n",
    "            rep_arg_2_rev_arg_sems_list.append(sample['reply']['rep_arg_2_rev_arg_dict_sem'])\n",
    "\n",
    "            reply_para_tokens_list.append(sample['reply']['sentences'])\n",
    "            tags_ids = [tags2id[tag] for tag in sample['reply']['bio_tags']]\n",
    "            reply_tags_list.append(tags_ids)\n",
    "            #reply for task1\n",
    "            reply_match_labels.append(sample['reply']['match_labels'])\n",
    "            reply_start_labels.append(sample['reply']['start_labels'])\n",
    "            reply_end_labels.append(sample['reply']['end_labels'])\n",
    "            # reply for task2\n",
    "\n",
    "            rev_arg_2_rep_arg_sems_list.append(sample['review']['rev_arg_2_rep_arg_dict_sem'])\n",
    "\n",
    "            #task2 total\n",
    "\n",
    "            arg_pairs = []\n",
    "            for rev_arg, rep_args in sample['review']['rev_arg_2_rep_arg_dict'].items():\n",
    "                for rep_arg in rep_args:\n",
    "                    arg_pairs.append((rev_arg, rep_arg))\n",
    "            true_arg_pairs_list.append(arg_pairs)\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "\n",
    "\n",
    "            pred_rev_args_dict, pred_rep_args_dict,pred_pair_args_list, pred_pair_args_2_list = \\\n",
    "                model.predict_span(review_para_tokens_list, review_tags_list,\n",
    "                              reply_para_tokens_list, reply_tags_list)\n",
    "\n",
    "        true_rev_args_list_span = extract_span_arguments_yi(review_match_labels, review_start_labels, review_end_labels)\n",
    "        all_true_rev_args_list.extend(true_rev_args_list_span)\n",
    "        pred_rev_args_list_span = extract_span_arguments_yi(pred_rev_args_dict['review_span_preds'], pred_rev_args_dict['review_start_preds'], pred_rev_args_dict['review_end_preds'])\n",
    "        all_pred_rev_args_list.extend(pred_rev_args_list_span)\n",
    "\n",
    "        true_rep_args_list_span = extract_span_arguments_yi(reply_match_labels, reply_start_labels, reply_end_labels)\n",
    "        all_true_rep_args_list.extend(true_rep_args_list_span)\n",
    "        pred_rep_args_list_span = extract_span_arguments_yi(pred_rep_args_dict['reply_span_preds'],\n",
    "                                                         pred_rep_args_dict['reply_start_preds'],\n",
    "                                                         pred_rep_args_dict['reply_end_preds'])\n",
    "        all_pred_rep_args_list.extend(pred_rep_args_list_span)\n",
    "\n",
    "        all_true_arg_pairs_list.extend(true_arg_pairs_list) \n",
    "\n",
    "        pred_arg_pairs_list = []\n",
    "        for pred_rep_args in pred_pair_args_list: \n",
    "            pred_arg_pairs = []\n",
    "\n",
    "            for rev_arg, rep_args in pred_rep_args.items():\n",
    "                for rep_arg, rep_arg_prob in zip(rep_args[0], rep_args[1]):\n",
    "                    pred_arg_pairs.append((rev_arg, rep_arg))\n",
    "\n",
    "            pred_arg_pairs_list.append(pred_arg_pairs)\n",
    "\n",
    "        pred_arg_pairs_2_list = []\n",
    "        for pred_rep_args_2 in pred_pair_args_2_list: \n",
    "            pred_arg_pairs = []\n",
    "\n",
    "            for rep_arg, rev_args in pred_rep_args_2.items():\n",
    "                for rev_arg, rev_arg_prob in zip(rev_args[0], rev_args[1]):\n",
    "                    pred_arg_pairs.append((rev_arg, rep_arg))\n",
    "\n",
    "            pred_arg_pairs_2_list.append(pred_arg_pairs)\n",
    "\n",
    "        all_pred_arg_pairs_list.extend(\n",
    "            [list(set(a + b)) for a, b in zip(pred_arg_pairs_list, pred_arg_pairs_2_list)]) \n",
    "        all_pred_arg_pairs_list_from_rev.extend([a for a in pred_arg_pairs_list])\n",
    "        all_pred_arg_pairs_list_from_rep.extend([b for b in pred_arg_pairs_2_list])  \n",
    "\n",
    "    args_pair_dict = args_metric(all_true_arg_pairs_list, all_pred_arg_pairs_list) \n",
    "\n",
    "    return  args_pair_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae39858-878c-4a9b-b952-beef09ad2d28",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb049b9-bb7e-4381-b165-a607318d2acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "> training arguments:\n",
      ">>> save_path: ./saved_models\n",
      ">>> device: 1\n",
      ">>> seed: 42\n",
      ">>> batch_size: 4\n",
      ">>> epochs: 2\n",
      ">>> showtime: 2000\n",
      ">>> base_encoder_lr: 1e-05\n",
      ">>> longformer_base_encoder_lr: 1e-05\n",
      ">>> finetune_lr: 0.001\n",
      ">>> warm_up: 0.05\n",
      ">>> weight_decay: 1e-05\n",
      ">>> early_num: 5\n",
      ">>> num_tags: 5\n",
      ">>> threshold: 0.3\n",
      ">>> hidden_size: 128\n",
      ">>> layers: 2\n",
      ">>> is_bi: False\n",
      ">>> bert_output_size: 768\n",
      ">>> mlp_size: 512\n",
      ">>> scale_factor: 2\n",
      ">>> dropout: 0.7\n",
      ">>> max_grad_norm: 1.0\n",
      ">>> num_heads: 4\n",
      ">>> att_dropout: 0.1\n",
      ">>> mrc_dropout: 0.7\n",
      ">>> lstm_dropout: 0.4\n",
      ">>> classifier_act_func: gelu\n",
      ">>> classifier_intermediate_hidden_size: 128\n",
      ">>> weight_start: 1.0\n",
      ">>> weight_end: 1.0\n",
      ">>> weight_span: 0.1\n",
      "Data loaded.\n",
      "Initializing model...\n",
      "Model initialized.\n",
      "Running epoch: 0\n",
      "100%|█████████████████████████████████████| 9971/9971 [1:33:13<00:00,  1.78it/s]\n",
      "  0%|                                                   | 0/473 [00:00<?, ?it/s]/home/nothing/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|█████████████████████████████████████████| 473/473 [01:45<00:00,  4.46it/s]\n",
      "********************best********************\n",
      "********************the performance in valid set...********************\n",
      "running time: 105.96105766296387\n",
      "total batch: 9971\n",
      "total pair f1:\t0.3366\n",
      "100%|█████████████████████████████████████████| 474/474 [01:46<00:00,  4.45it/s]\n",
      "********************the performance in test set...********************\n",
      "total pair f1:\t0.3071\n",
      "Running epoch: 1\n",
      "100%|█████████████████████████████████████| 9971/9971 [1:33:16<00:00,  1.78it/s]\n",
      "100%|█████████████████████████████████████████| 473/473 [01:59<00:00,  3.96it/s]\n",
      "********************best********************\n",
      "********************the performance in valid set...********************\n",
      "running time: 119.41576409339905\n",
      "total batch: 19942\n",
      "total pair f1:\t0.3891\n",
      "100%|█████████████████████████████████████████| 474/474 [01:58<00:00,  3.99it/s]\n",
      "********************the performance in test set...********************\n",
      "total pair f1:\t0.3631\n"
     ]
    }
   ],
   "source": [
    "config = get_config()\n",
    "now = datetime.datetime.now()\n",
    "now_time_string = \"{:0>4d}{:0>2d}{:0>2d}_{:0>2d}{:0>2d}{:0>2d}_{:0>5d}\".format(\n",
    "    now.year, now.month, now.day, now.hour, now.minute, now.second, config.seed)\n",
    "save_path = './saved_models'\n",
    "save_path = os.path.join(save_path, now_time_string)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "else:\n",
    "    print(\"save_path exists!!\")\n",
    "    exit(1)\n",
    "with open(os.path.join(save_path, \"config.json\"), \"w\") as fp:\n",
    "    json.dump(config.__dict__, fp)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.warning('> training arguments:')\n",
    "for arg in vars(config):\n",
    "    logger.warning('>>> {0}: {1}'.format(arg, getattr(config, arg)))\n",
    "\n",
    "\n",
    "train_list_task1_review,train_list_task1_reply, train_list_task2_review,train_list_task2_reply= \\\n",
    "    load_data_new_sample('./data/processed/train.txt.bioes')\n",
    "\n",
    "\n",
    "\n",
    "dev_list = load_data('./data/processed/dev.txt.bioes')\n",
    "test_list = load_data('./data/processed/test.txt.bioes')\n",
    "\n",
    "\n",
    "train_list=train_list_task1_review+train_list_task1_reply+train_list_task2_review+train_list_task2_reply\n",
    "\n",
    "\n",
    "train_len = len(train_list)\n",
    "train_iter_len = (train_len // config.batch_size) + 1\n",
    "if train_len % config.batch_size == 0:\n",
    "    train_iter_len -= 1\n",
    "num_training_steps = train_iter_len * config.epochs\n",
    "num_warmup_steps = int(num_training_steps * config.warm_up)\n",
    "logger.warning('Data loaded.')\n",
    "\n",
    "logger.warning('Initializing model...')\n",
    "model = BERT_BiLSTM_CRF(config)\n",
    "model.cuda()\n",
    "logger.warning('Model initialized.')\n",
    "\n",
    "\n",
    "longformer_model_para = list(model.longformer.parameters())\n",
    "lstm_para=list(model.am_bilstm.parameters())\n",
    "other_model_para = list(set(model.parameters()) - set(longformer_model_para)-set(lstm_para))\n",
    "\n",
    "\n",
    "\n",
    "longformer_base_encoder_lr=1e-5\n",
    "lstm_para_lr=1e-3\n",
    "finetune_lr=1e-3\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for p in other_model_para if len(p.data.size()) > 1], 'weight_decay': config.weight_decay},\n",
    "    {'params': [p for p in other_model_para if len(p.data.size()) == 1], 'weight_decay': 0.0},\n",
    "    {'params': longformer_model_para, 'lr': longformer_base_encoder_lr},\n",
    "    {'params': lstm_para, 'lr': lstm_para_lr}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, finetune_lr)\n",
    "\n",
    "total_batch, early_stop = 0, 0\n",
    "best_batch, best_f1 = 0, 0.0\n",
    "\n",
    "\n",
    "random.shuffle(train_list)\n",
    "\n",
    "\n",
    "for epoch_i in range(config.epochs):\n",
    "    logger.warning(\"Running epoch: {}\".format(epoch_i))\n",
    "    loss_0, loss_1 = None, None\n",
    "    last_loss_0, last_loss_1 = 0, 0\n",
    "    bw_flag = False\n",
    "\n",
    "    batch_id = 0\n",
    "    for batch_i in tqdm(range(train_iter_len)):\n",
    "        try:\n",
    "            model.train()\n",
    "            train_batch = train_list[batch_i * config.batch_size:(batch_i + 1) * config.batch_size]\n",
    "            if len(train_batch) <= 1:\n",
    "                    continue\n",
    "\n",
    "            para_tokens_list= []\n",
    "            match_labels, start_labels,end_labels = [], [],[]\n",
    "\n",
    "            para_tokens_list_for_2 = []\n",
    "\n",
    "            rr_arg_pair_list=[]\n",
    "\n",
    "            sample_tags_list=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            tt=[]\n",
    "\n",
    "            for sample in train_batch:\n",
    "                sample_tags_list.append(sample['tag'])\n",
    "\n",
    "                if \"task1\" in sample['tag']:\n",
    "                    para_tokens_list.append(sample['sentences'])\n",
    "\n",
    "                    para_tokens_list_for_2.append([])\n",
    "                    rr_arg_pair_list.append({})\n",
    "\n",
    "                    match_labels.append(sample['match_labels'])\n",
    "                    start_labels.append(sample['start_labels'])\n",
    "                    end_labels.append(sample['end_labels'])\n",
    "\n",
    "\n",
    "\n",
    "                elif \"task2\" in sample['tag']:\n",
    "                    para_tokens_list.append(sample['review_sentences'])\n",
    "                    para_tokens_list_for_2.append(sample['reply_sentences'])\n",
    "\n",
    "                    rr_arg_pair_list.append(sample['rr_arg_dict'])\n",
    "\n",
    "                    match_labels.append(sample['match_labels'])\n",
    "                    start_labels.append(sample['start_labels'])\n",
    "                    end_labels.append(sample['end_labels'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            loss = model(para_tokens_list,para_tokens_list_for_2,rr_arg_pair_list,match_labels,start_labels,end_labels,tag_list_o=sample_tags_list)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            total_batch += 1\n",
    "            batch_id += 1\n",
    "        except UnboundLocalError:\n",
    "            print('Bad')\n",
    "            continue\n",
    "\n",
    "    # evaluate\n",
    "    t_start = time.time()\n",
    "\n",
    "    dev_args_pair_dict=evaluate(model, dev_list)\n",
    "\n",
    "    t_end = time.time()\n",
    "    total_f1 = dev_args_pair_dict['f1']\n",
    "    if total_f1 > best_f1:\n",
    "        early_stop = 0\n",
    "        best_f1 = total_f1\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, 'best_model.mdl'))\n",
    "        logger.warning('*' * 20 + 'best' + '*' * 20)\n",
    "        best_batch = total_batch\n",
    "        logger.warning('*' * 20 + 'the performance in valid set...' + '*' * 20)\n",
    "        logger.warning('running time: {}'.format(t_end - t_start))\n",
    "        logger.warning('total batch: {}'.format(total_batch))\n",
    "        logger.warning('total pair f1:\\t{:.4f}'.format(\n",
    "            dev_args_pair_dict['f1']))\n",
    "\n",
    "        test_args_pair_dict = evaluate(\n",
    "            model, test_list)\n",
    "        logger.warning('*' * 20 + 'the performance in test set...' + '*' * 20)\n",
    "        logger.warning('total pair f1:\\t{:.4f}'.format(\n",
    "            test_args_pair_dict['f1']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d9d2a-d578-472e-b499-db49ebd5f533",
   "metadata": {},
   "source": [
    "Please note that the best performing model is saved in 'saved_models' folder, it also has a json file with the expirement results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71057a6d-807f-47a9-aca6-28ea8db85c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
